{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fL5NnUi0zFd1"
   },
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gjp2H5MIzJdx"
   },
   "outputs": [],
   "source": [
    "# In order to to read the Ciffar data set, we must define the unpickle function: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). \n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sVmLmijXzN8e",
    "outputId": "729e1fa1-1037-4b47-878c-6e7afbd64104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "40543ADvzbpX"
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data_1 = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/data_batch_1\")\n",
    "data_2 = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/data_batch_2\")\n",
    "data_3 = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/data_batch_3\")\n",
    "data_4 = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/data_batch_4\")\n",
    "data_5 = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/data_batch_5\")\n",
    "test_batch = unpickle(\"/content/drive/My Drive/Colab Notebooks/cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UOXQCipp42zu"
   },
   "outputs": [],
   "source": [
    "# For the sake of computational cost, we will work on gray scale images - without feature normalization\n",
    "data_1[b\"data\"] = data_1[b\"data\"].astype(float)[:,0:1024]\n",
    "data_2[b\"data\"] = data_2[b\"data\"].astype(float)[:,0:1024]\n",
    "data_3[b\"data\"] = data_3[b\"data\"].astype(float)[:,0:1024]\n",
    "data_4[b\"data\"] = data_4[b\"data\"].astype(float)[:,0:1024]\n",
    "data_5[b\"data\"] = data_5[b\"data\"].astype(float)[:,0:1024]\n",
    "test_batch[b\"data\"] = test_batch[b\"data\"].astype(float)[:,0:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9VOVNXy-46_4"
   },
   "outputs": [],
   "source": [
    "#Preparing our data set for 5 fold validation. a list of 4 fold training set (training_data_n , training_labels_n) \n",
    "#and a fold for validation (validation_data_n, validation_labels_n) \n",
    "training_data_1 = []\n",
    "training_data_1.append(data_1[b\"data\"])\n",
    "training_data_1.append(data_2[b\"data\"])\n",
    "training_data_1.append(data_3[b\"data\"])\n",
    "training_data_1.append(data_4[b\"data\"])\n",
    "training_labels_1 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] \n",
    "validation_data_1 = data_5[b\"data\"]\n",
    "validation_labels_1 = data_5[b\"labels\"]\n",
    "\n",
    "training_data_2 = []\n",
    "training_data_2.append(data_1[b\"data\"])\n",
    "training_data_2.append(data_2[b\"data\"])\n",
    "training_data_2.append(data_3[b\"data\"])\n",
    "training_data_2.append(data_5[b\"data\"])\n",
    "training_labels_2 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_5[b\"labels\"] \n",
    "validation_data_2 = data_4[b\"data\"]\n",
    "validation_labels_2 = data_4[b\"labels\"]\n",
    "\n",
    "training_data_3 = []\n",
    "training_data_3.append(data_1[b\"data\"])\n",
    "training_data_3.append(data_2[b\"data\"])\n",
    "training_data_3.append(data_4[b\"data\"])\n",
    "training_data_3.append(data_5[b\"data\"])\n",
    "training_labels_3 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "validation_data_3 = data_3[b\"data\"]\n",
    "validation_labels_3 = data_3[b\"labels\"]\n",
    "\n",
    "training_data_4 = []\n",
    "training_data_4.append(data_1[b\"data\"])\n",
    "training_data_4.append(data_3[b\"data\"])\n",
    "training_data_4.append(data_4[b\"data\"])\n",
    "training_data_4.append(data_5[b\"data\"])\n",
    "training_labels_4 = data_1[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "validation_data_4 = data_2[b\"data\"]\n",
    "validation_labels_4 = data_2[b\"labels\"]\n",
    "\n",
    "training_data_5 = []\n",
    "training_data_5.append(data_2[b\"data\"])\n",
    "training_data_5.append(data_3[b\"data\"])\n",
    "training_data_5.append(data_4[b\"data\"])\n",
    "training_data_5.append(data_5[b\"data\"])\n",
    "training_labels_5 = data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "validation_data_5 = data_1[b\"data\"]\n",
    "validation_labels_5 = data_1[b\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CVJ9h4wDG2zO"
   },
   "outputs": [],
   "source": [
    "#preparing our data set with feature normalization\n",
    "normalized_data_1 = (data_1[b\"data\"].astype(float)[:,0:1024] - np.mean(data_1[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(data_1[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])\n",
    "normalized_data_2 = (data_2[b\"data\"].astype(float)[:,0:1024] - np.mean(data_2[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(data_2[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])\n",
    "normalized_data_3 = (data_3[b\"data\"].astype(float)[:,0:1024] - np.mean(data_3[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(data_3[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])\n",
    "normalized_data_4 = (data_4[b\"data\"].astype(float)[:,0:1024] - np.mean(data_4[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(data_4[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])\n",
    "normalized_data_5 = (data_5[b\"data\"].astype(float)[:,0:1024] - np.mean(data_5[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(data_5[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])\n",
    "normalized_test_batch = (test_batch[b\"data\"].astype(float)[:,0:1024] - np.mean(test_batch[b\"data\"].astype(float)[:,0:1024],axis=1)[:,np.newaxis])/(np.std(test_batch[b\"data\"].astype(float)[:,0:1024], axis=1)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4C91dQZ1JZ8Z"
   },
   "outputs": [],
   "source": [
    "#Preparing our normalized data set for 5 fold validation. a list of 4 fold training set (normalized_training_data_n , normalized_training_labels_n) \n",
    "#and a fold for validation (normalized_validation_data_n, normalized_validation_labels_n) \n",
    "normalized_training_data_1 = []\n",
    "normalized_training_data_1.append(normalized_data_1)\n",
    "normalized_training_data_1.append(normalized_data_2)\n",
    "normalized_training_data_1.append(normalized_data_3)\n",
    "normalized_training_data_1.append(normalized_data_4)\n",
    "training_labels_1 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] \n",
    "normalized_validation_data_1 = normalized_data_5\n",
    "validation_labels_1 = data_5[b\"labels\"]\n",
    "\n",
    "normalized_training_data_2 = []\n",
    "normalized_training_data_2.append(normalized_data_1)\n",
    "normalized_training_data_2.append(normalized_data_2)\n",
    "normalized_training_data_2.append(normalized_data_3)\n",
    "normalized_training_data_2.append(normalized_data_5)\n",
    "training_labels_2 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_5[b\"labels\"] \n",
    "normalized_validation_data_2 = normalized_data_4\n",
    "validation_labels_2 = data_4[b\"labels\"]\n",
    "\n",
    "normalized_training_data_3 = []\n",
    "normalized_training_data_3.append(normalized_data_1)\n",
    "normalized_training_data_3.append(normalized_data_2)\n",
    "normalized_training_data_3.append(normalized_data_4)\n",
    "normalized_training_data_3.append(normalized_data_5)\n",
    "training_labels_3 = data_1[b\"labels\"] + data_2[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "normalized_validation_data_3 = normalized_data_3\n",
    "validation_labels_3 = data_3[b\"labels\"]\n",
    "\n",
    "normalized_training_data_4 = []\n",
    "normalized_training_data_4.append(normalized_data_1)\n",
    "normalized_training_data_4.append(normalized_data_3)\n",
    "normalized_training_data_4.append(normalized_data_4)\n",
    "normalized_training_data_4.append(normalized_data_5)\n",
    "training_labels_4 = data_1[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "normalized_validation_data_4 = normalized_data_2\n",
    "validation_labels_4 = data_2[b\"labels\"]\n",
    "\n",
    "normalized_training_data_5 = []\n",
    "normalized_training_data_5.append(normalized_data_2)\n",
    "normalized_training_data_5.append(normalized_data_3)\n",
    "normalized_training_data_5.append(normalized_data_4)\n",
    "normalized_training_data_5.append(normalized_data_5)\n",
    "training_labels_5 = data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"] \n",
    "normalized_validation_data_5 = normalized_data_1\n",
    "validation_labels_5 = data_1[b\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yvejmmcU0rwM"
   },
   "outputs": [],
   "source": [
    "#DistanceCalculation function --> inputs: training data as a list of 4 training_data or 4 normalized_training data, and validation_data or normalized_validation_data \n",
    "#Output:  a matrix that includes the distance of every validation image from each of the training image \n",
    "# as a distance formula, i have used the formula which is described in the \"No-loop implementation\" part of the https://ljvmiranda921.github.io/notebook/2017/02/09/k-nearest-neighbors/\n",
    "def DistanceCalculation(training_data, validation_data):\n",
    "  matrices = []\n",
    "  sumsquared_validation = np.diagonal(np.dot(validation_data, validation_data.T)) #b^2\n",
    "  \n",
    "  for i in training_data:\n",
    "      sumsquared_training = np.diagonal(np.dot(i, i.T))[:, np.newaxis] #a^2\n",
    "      matrices.append(np.sqrt(sumsquared_training + sumsquared_validation - 2 * i.dot(validation_data.T))) # a^2 + b^2 -2*a*b\n",
    "  \n",
    "  distances = np.concatenate((matrices[0],matrices[1],matrices[2],matrices[3]),axis=0) \n",
    "\n",
    "  return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KvQUxu5a_2No"
   },
   "outputs": [],
   "source": [
    "#KNN function --> input: a distances matrix (a number of images in the training data * a number of images in the validation or test data set)\n",
    "#output: the accuracy\n",
    "def KNN(distances,training_lables, validation_labels,k):\n",
    "  \n",
    "\n",
    "    #finding the indices of k smallest distances\n",
    "    sorted_distances_indices = np.argsort(distances, axis=0)\n",
    "    Ksmallest_distances_indices = sorted_distances_indices[0:k, ]\n",
    " \n",
    "    #Finding the labels of K smallest distances using their indices\n",
    "    Ksmallest_labels = np.zeros((k,10000))\n",
    "    for i in range(0,10000):\n",
    "        for j in range(0,k):\n",
    "            Ksmallest_labels[j,i] = Ksmallest_labels[j,i] + training_lables[Ksmallest_distances_indices[j,i]]\n",
    "  \n",
    "  \n",
    "    #predicted label: most frequent label in k smallest distances'label\n",
    "    #argmax(array, axis = None, out = None) : Returns indices of the max element of the array in a particular axis\n",
    "    #bincount: Count number of occurrences of each value in array of non-negative ints.\n",
    "    predicted_labels = []\n",
    "    for i in range(0,10000):\n",
    "        a = Ksmallest_labels[:,i].astype(int)\n",
    "        predicted_labels.append(np.bincount(a).argmax())\n",
    "  \n",
    "\n",
    "  #comparing our result and calculating accuracy\n",
    "    a = 0\n",
    "    for i in range(0,10000):\n",
    "        if predicted_labels[i] == validation_labels[i]:\n",
    "            a = a + 1\n",
    "  \n",
    "    accuracy = a/10000\n",
    "  \n",
    "    return (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-O_NyTiR_2oV"
   },
   "outputs": [],
   "source": [
    "distance_1 = DistanceCalculation(training_data_1, validation_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "xQHbIWVBViAe",
    "outputId": "9ebd5bee-7b70-4285-f3f2-6c66ee731590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.2733, 0.2345, 0.2446, 0.2512, 0.2558, 0.2548, 0.2571, 0.2583, 0.2631, 0.2613, 0.2622, 0.2603, 0.2572, 0.2575, 0.2597, 0.2588, 0.2585, 0.259, 0.2581, 0.2577]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: first set of folds wihtout feature normalization\n",
    "Acc_1 = []\n",
    "for i in range(1,21):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    Acc_1.append(KNN(distances = distance_1,training_lables = training_labels_1, validation_labels = validation_labels_1,k=i))\n",
    "\n",
    "\n",
    "\n",
    "print(Acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "3gxrzhBp_27l",
    "outputId": "96858553-dd3c-4990-d508-598f80bc02ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.3467, 0.3148, 0.3347, 0.3461, 0.3533, 0.3575, 0.3577, 0.3612, 0.3609, 0.3594, 0.3613, 0.3577, 0.3546, 0.3567, 0.3574, 0.3565, 0.3561, 0.3583, 0.3592, 0.3591]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: first set of folds wiht feature normalization\n",
    "normdistances_1 = DistanceCalculation(normalized_training_data_1, normalized_validation_data_1)\n",
    "normalized_Acc_1 = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    normalized_Acc_1.append(KNN(distances = normdistances_1,training_lables = training_labels_1, validation_labels = validation_labels_1,k=i))\n",
    "\n",
    "    \n",
    "\n",
    "print(normalized_Acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "s98pFO8x_389",
    "outputId": "1e8ec560-ad72-4ed6-a049-eef94b84c8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.272, 0.2357, 0.2532, 0.2563, 0.2584, 0.2614, 0.2617, 0.2641, 0.2633, 0.268, 0.2671, 0.264, 0.2655, 0.263, 0.2634, 0.2614, 0.2624, 0.2584, 0.2591, 0.2581]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: second set of folds wihtout feature normalization\n",
    "distances_2 = DistanceCalculation(training_data_2,validation_data_2)\n",
    "Acc_2 = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    Acc_2.append(KNN(distances_2, training_labels_2, validation_labels_2, i))\n",
    "\n",
    "print(Acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "9UfVu3mI_4ZG",
    "outputId": "8884427b-337a-4985-8bf2-29edfed9a629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.3454, 0.3126, 0.3373, 0.3473, 0.3509, 0.3539, 0.3544, 0.3606, 0.3612, 0.3636, 0.3649, 0.3656, 0.3633, 0.3617, 0.3632, 0.3605, 0.3592, 0.3608, 0.361, 0.3596]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: second set of folds wiht feature normalization\n",
    "normdistances_2 = DistanceCalculation(normalized_training_data_2,normalized_validation_data_2)\n",
    "normalized_Acc_2 = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    normalized_Acc_2.append(KNN(normdistances_2, training_labels_2, validation_labels_2, i))\n",
    "\n",
    "print(normalized_Acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "ZgDyrXI-_4xs",
    "outputId": "361518b9-17cc-47fc-87d7-49b6c717ab6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.2797, 0.2412, 0.2583, 0.2638, 0.2657, 0.2679, 0.2676, 0.2659, 0.2674, 0.2683, 0.2661, 0.2636, 0.263, 0.2623, 0.2617, 0.2629, 0.2612, 0.259, 0.26, 0.2587]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: third set of folds wihtout feature normalization\n",
    "distances_3 = DistanceCalculation(training_data_3,validation_data_3)\n",
    "Acc_3 = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    Acc_3.append(KNN(distances_3, training_labels_3, validation_labels_3, i))\n",
    "\n",
    "print(Acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "sShtwjyy_5G7",
    "outputId": "0978ee0f-2a2a-4be5-e01d-29b4a63fa620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.351, 0.3199, 0.3433, 0.3512, 0.3592, 0.3632, 0.3647, 0.3627, 0.3656, 0.3672, 0.3656, 0.3674, 0.3677, 0.3678, 0.3682, 0.3674, 0.3654, 0.3644, 0.3659, 0.3669]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: third set of folds with feature normalization\n",
    "normdistances_3 = DistanceCalculation(normalized_training_data_3,normalized_validation_data_3)\n",
    "normalized_Acc_3 = []\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    normalized_Acc_3.append(KNN(normdistances_3, training_labels_3, validation_labels_3, i))\n",
    "\n",
    "print(normalized_Acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "CywznVmiAUtL",
    "outputId": "a0f3b65f-df06-4f54-d767-34801166dd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.2692, 0.2371, 0.2518, 0.2601, 0.2613, 0.2577, 0.2606, 0.2588, 0.2589, 0.2588, 0.2572, 0.2553, 0.257, 0.255, 0.2545, 0.2559, 0.2531, 0.2523, 0.2518, 0.2525]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: fourth set of folds without feature normalization\n",
    "distances_4 = DistanceCalculation(training_data_4,validation_data_4)\n",
    "Acc_4 = []\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    Acc_4.append(KNN(distances_4, training_labels_4, validation_labels_4, i))\n",
    "\n",
    "print(Acc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "1JNyw925AZs-",
    "outputId": "28a56189-e6fe-4c96-b1e7-8397b783ebf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.3414, 0.3017, 0.325, 0.337, 0.3421, 0.3404, 0.3424, 0.3476, 0.3456, 0.3482, 0.3493, 0.3471, 0.3429, 0.3442, 0.3465, 0.3466, 0.3465, 0.3467, 0.3458, 0.3455]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: fourth set of folds with feature normalization\n",
    "normdistances_4 = DistanceCalculation(normalized_training_data_4,normalized_validation_data_4)\n",
    "normalized_Acc_4 = []\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    normalized_Acc_4.append(KNN(normdistances_4, training_labels_4, validation_labels_4, i))\n",
    "\n",
    "\n",
    "print(normalized_Acc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjH1yoePAcXK"
   },
   "outputs": [],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: fifth set of folds without feature normalization\n",
    "distances_5 = DistanceCalculation(training_data_5,validation_data_5)\n",
    "Acc_5 = []\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    Acc_5.append(KNN(distances_5, training_labels_5, validation_labels_5, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HEV6t0XecmdQ",
    "outputId": "797c5f18-4e0b-4151-fd7f-6ceace3eecaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2802, 0.2374, 0.2526, 0.2579, 0.2634, 0.2656, 0.2638, 0.2634, 0.2659, 0.2688, 0.2665, 0.2638, 0.2643, 0.261, 0.2625, 0.259, 0.2576, 0.2587, 0.2586, 0.2583]\n"
     ]
    }
   ],
   "source": [
    "print(Acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "vlMl_hxVAfFs",
    "outputId": "8ca69a23-bc6c-41a3-b9a4-eddbb9d42199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[0.3504, 0.3199, 0.3342, 0.3383, 0.3439, 0.3481, 0.3486, 0.3522, 0.3541, 0.3521, 0.3533, 0.3542, 0.3551, 0.3531, 0.3559, 0.3575, 0.355, 0.3544, 0.3534, 0.3544]\n"
     ]
    }
   ],
   "source": [
    "#finding the accuracy for k between 1 and 20 - data set: fifth set of folds with feature normalization\n",
    "normdistances_5 = DistanceCalculation(normalized_training_data_5,normalized_validation_data_5)\n",
    "normalized_Acc_5 = []\n",
    "for i in range(1,21):\n",
    "    print(i)\n",
    "    normalized_Acc_5.append(KNN(normdistances_5, training_labels_5, validation_labels_5, i))\n",
    "\n",
    "print(normalized_Acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tC6mDWDCNG6s"
   },
   "outputs": [],
   "source": [
    "#now the proper k has been selected: proper K without feature normalization = 1, proper K with feature normalization = 14\n",
    "#preparing our data for the test phase without feature normalization\n",
    "training_data_final = []\n",
    "training_data_final.append(data_1[b\"data\"])\n",
    "training_data_final.append(data_2[b\"data\"])\n",
    "training_data_final.append(data_3[b\"data\"])\n",
    "training_data_final.append(data_4[b\"data\"])\n",
    "training_data_final.append(data_5[b\"data\"])\n",
    "\n",
    "training_labels_final = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"]  \n",
    "test_data = test_batch[b\"data\"]\n",
    "test_labels = test_batch[b\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1e3bzB6OOa-m"
   },
   "outputs": [],
   "source": [
    "#preparing our data for the test phase with feature normalization\n",
    "normalized_training_data_final = []\n",
    "normalized_training_data_final.append(normalized_data_1)\n",
    "normalized_training_data_final.append(normalized_data_2)\n",
    "normalized_training_data_final.append(normalized_data_3)\n",
    "normalized_training_data_final.append(normalized_data_4)\n",
    "normalized_training_data_final.append(normalized_data_5)\n",
    "\n",
    "training_labels_final = data_1[b\"labels\"] + data_2[b\"labels\"] + data_3[b\"labels\"] + data_4[b\"labels\"] + data_5[b\"labels\"]  \n",
    "normalized_test_data = normalized_test_batch\n",
    "test_labels = test_batch[b\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "D7E7yqrrBIFd"
   },
   "outputs": [],
   "source": [
    "distances_test = DistanceCalculation(training_data_final,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GmV_y8Fxirt2",
    "outputId": "dd8a9fa4-380c-42fe-d2ff-8ea4bb5ba7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2831\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy, the training and test data set have not been normalized\n",
    "Acc_test = KNN(distances_test, training_labels_final, test_labels, 1)\n",
    "print(Acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iXSCxCIEisUB"
   },
   "outputs": [],
   "source": [
    "normalized_distance_test = DistanceCalculation(normalized_training_data_final,normalized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Xrvd_Bi3QG43",
    "outputId": "7b1b5c5c-e710-4f66-c441-b6d88c98b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3607\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy, both of the training and test data set have been normalized\n",
    "Acc_test_normalized = KNN(normalized_distance_test, training_labels_final, test_labels, 14)\n",
    "print(Acc_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FiXEv5Nvi2PR"
   },
   "outputs": [],
   "source": [
    "normalized_distance_test_noramal_test_data = DistanceCalculation(normalized_training_data_final,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "w0_t0JARidEu",
    "outputId": "256c06d7-5611-45e1-9010-4d4c9a902e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3607\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy, just the training set has been normalized\n",
    "Acc_test_normalized_regular_test_data = KNN(normalized_distance_test_noramal_test_data, training_labels_final, test_labels, 14)\n",
    "print(Acc_test_normalized_regular_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgR_uBxeTAme"
   },
   "outputs": [],
   "source": [
    "##we can see that we have reached the same accuracy for Acc_test_normalized_regular_test_data and Acc_test_normalized which make sense, "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ciffar-image-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
